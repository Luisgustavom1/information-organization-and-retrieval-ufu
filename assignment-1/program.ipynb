%%writefile modelo_booleano.py
#!usr/bin/bash python

import nltk
import sys

nltk.download("stopwords")
nltk.download('punkt')

base_file = sys.argv[1]
consult_file = sys.argv[2] 

print(base_file)
print(consult_file)

def extract_terms(file_name):
  with open(file_name, 'r', encoding='utf-8') as f:
    text = f.read()
    print(remove_stopwords(tokenize_text(text))) 

def tokenize_text(text):
  return nltk.word_tokenize(text)

def remove_stopwords(terms):
  stopwords = get_stopwords()
  clean_terms = []

  for term in terms:
    if (not term in stopwords):
      clean_terms.append(term)

  return clean_terms

def get_stopwords():
  stopwords_list = nltk.corpus.stopwords.words("portuguese")+[' ', '.', '...', ',', '!', '?', '\n', '\r\n']
  stopwords = {}

  for stopword in stopwords_list:
    stopwords[stopword] = stopword

  return stopwords

with open(base_file, 'r', encoding='utf-8') as f:
    for file in f.readlines():
      extract_terms(file.replace('\n', ''))
